{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 reaction folders.\n",
      "Parameters loaded from: reaction_parameters_2025-12-01_15-36-13.csv\n",
      "Starting individual reaction processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cef48289cb4aa78f975f63f5feec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Reactions:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning in 01_10-0_Dil-1_f1_2025-12-01_15-36-13/Emission_nir: Mismatched data length. Adjusting to fit theoretical time points.\n",
      "  -> Cut off 501 wavelengths < 500nm for 01_10-0_Dil-1_f1_2025-12-01_15-36-13/Emission_vis\n",
      "Warning in 01_10-0_Dil-1_f1_2025-12-01_15-36-13/Emission_vis: Mismatched data length. Adjusting to fit theoretical time points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arelling\\Desktop\\git\\kinetic-setup\\publication\\data_analysis\\data_analysis.py:201: RuntimeWarning: divide by zero encountered in divide\n",
      "  energies = HC_CONST / wavelengths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual processing complete.\n",
      "Compiling global experiment traces...\n",
      "Warning: NaNs detected in 01_10-0_Dil-1_f1_2025-12-01_15-36-13 during smoothing. Applying interpolation.\n",
      "Warning: NaNs detected in 01_10-0_Dil-1_f1_2025-12-01_15-36-13 during smoothing. Applying interpolation.\n",
      "Compiling global datasets...\n",
      "Summary files saved to: \\\\Gfs01\\g11\\FluoSpec\\Alle\\Alex_Relling\\Austausch\\kinetic_setup_data\\2025-12-01\n",
      "Extracting snapshots for times: [] s\n",
      "Workflow finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Automated Kinetic Data Processing Pipeline\n",
    "# \n",
    "# **Description:** This notebook automates the processing of time-resolved fluorescence spectroscopy data. \n",
    "# It performs data cleaning, Savitzky-Golay smoothing, feature extraction (peak intensity, position, FWHM), \n",
    "# and compiles aggregate statistics for all reactions in the dataset.\n",
    "#\n",
    "# **Dependencies:** pandas, numpy, scipy, pathlib, tqdm, data_analysis (local module)\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm  # Provides progress bars\n",
    "\n",
    "# Import local analysis module (refactored code)\n",
    "import data_analysis as da\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 1. Configuration and Parameters\n",
    "# Define file paths and processing parameters here for reproducibility.\n",
    "\n",
    "# %%\n",
    "# Input Directory (Use 'r' for raw string to handle Windows backslashes)\n",
    "# Update this path to the current experiment date\n",
    "DATA_DIRECTORY = Path(r'\\\\Gfs01\\g11\\FluoSpec\\Alle\\Alex_Relling\\Austausch\\kinetic_setup_data\\2025-12-01')\n",
    "\n",
    "# Smoothing Parameters (Savitzky-Golay filter)\n",
    "SMOOTH_WINDOW1 = 11\n",
    "SMOOTH_POLY1 = 2\n",
    "\n",
    "SMOOTH_WINDOW2 = 11\n",
    "SMOOTH_POLY2 = 2\n",
    "\n",
    "# Feature Extraction Thresholds\n",
    "INTENSITY_THRESHOLD = 50.0  # Min counts to consider a real peak\n",
    "TIME_THRESHOLD = 100.0      # Time (s) until which low intensity implies no peak\n",
    "\n",
    "# Downsampling Settings (for plotting large datasets)\n",
    "CUTOFF_TIME = 600           # Seconds (high res before this, low res after)\n",
    "LATE_INTERVAL = 10          # Interval (s) for late-time data\n",
    "\n",
    "# Snapshots to extract (in seconds)\n",
    "SNAPSHOT_TIMES = []\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2. Load Metadata\n",
    "# Identify reaction folders and load the corresponding experimental parameters.\n",
    "\n",
    "# %%\n",
    "# Identify valid reaction folders (assumes folder names start with a digit, e.g., '001_Reaction')\n",
    "reaction_folders = [\n",
    "    f.name for f in DATA_DIRECTORY.iterdir() \n",
    "    if f.is_dir() and f.name[0].isdigit()\n",
    "]\n",
    "print(f\"Found {len(reaction_folders)} reaction folders.\")\n",
    "\n",
    "# Load Reaction Parameters (Frequency, Number of measurements, etc.)\n",
    "try:\n",
    "    # distinct file search to ensure we grab the right csv\n",
    "    param_file = list(DATA_DIRECTORY.glob('reaction_parameters*.csv'))[0]\n",
    "    reaction_params_df = pd.read_csv(param_file)\n",
    "    print(f\"Parameters loaded from: {param_file.name}\")\n",
    "except IndexError:\n",
    "    raise FileNotFoundError(\"CRITICAL: 'reaction_parameters.csv' not found in directory.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3. Primary Processing Loop\n",
    "# Iterate through each folder to clean, smooth, and extract features.\n",
    "# *Note: Processing is grouped per folder to minimize network I/O latency.*\n",
    "\n",
    "# %%\n",
    "print(\"Starting individual reaction processing...\")\n",
    "\n",
    "for folder in tqdm(reaction_folders, desc=\"Processing Reactions\"):\n",
    "    \n",
    "    # A. Standardize Time Axis (Clean)\n",
    "    # Aligns raw data columns to theoretical time points based on frequency\n",
    "    da.standardize_time_axis(\n",
    "        directory=DATA_DIRECTORY, \n",
    "        folder=folder, \n",
    "        reaction_params_df=reaction_params_df\n",
    "    )\n",
    "    \n",
    "    # B. Spectral Smoothing\n",
    "    # Applies Savitzky-Golay filter along the wavelength axis\n",
    "    da.apply_smoothing(\n",
    "        directory=DATA_DIRECTORY, \n",
    "        folder=folder, \n",
    "        window_length=SMOOTH_WINDOW1, \n",
    "        polyorder=SMOOTH_POLY1\n",
    "    )\n",
    "\n",
    "    da.merge_vis_nir_spectra(\n",
    "        directory=DATA_DIRECTORY,\n",
    "        folder=folder,\n",
    "        stitch_wavelength=930.0,    # Adjust if needed\n",
    "        stitch_window=10.0,         # Adjust if needed\n",
    "        min_signal_threshold=50.0    # Adjust if noise is higher\n",
    "    )\n",
    "\n",
    "    # Generates heatmaps immediately after smoothing\n",
    "    da.plot_reaction_heatmap(\n",
    "        directory=DATA_DIRECTORY,\n",
    "        folder=folder\n",
    "    )\n",
    "    # C. Data Reduction (Downsampling)\n",
    "    # Creates smaller files for quick visualization\n",
    "    da.downsample_temporal_data(\n",
    "        directory=DATA_DIRECTORY, \n",
    "        folder=folder, \n",
    "        cutoff_time=CUTOFF_TIME, \n",
    "        late_interval=LATE_INTERVAL\n",
    "    )\n",
    "    \n",
    "    # D. Feature Extraction\n",
    "    # Calculates Peak Max, Peak Position (nm), and FWHM (eV)\n",
    "    da.extract_spectral_features(\n",
    "        directory=DATA_DIRECTORY, \n",
    "        folder=folder,\n",
    "        intensity_threshold=INTENSITY_THRESHOLD,\n",
    "        time_threshold=TIME_THRESHOLD\n",
    "    )\n",
    "\n",
    "print(\"Individual processing complete.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 4. Global Aggregation\n",
    "# Compile the extracted features from all reactions into summary datasets for comparative analysis.\n",
    "\n",
    "# %%\n",
    "print(\"Compiling global experiment traces...\")\n",
    "\n",
    "da.compile_experiment_traces(\n",
    "    directory=DATA_DIRECTORY, \n",
    "    folders=reaction_folders,\n",
    "    window_length=SMOOTH_WINDOW2,\n",
    "    polyorder=SMOOTH_POLY2\n",
    ")\n",
    "\n",
    "print(f\"Summary files saved to: {DATA_DIRECTORY}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 5. Snapshot Extraction\n",
    "# Extract full spectral data at specific time points (defined in config) for all reactions. \n",
    "# Creates normalized and raw intensity files.\n",
    "\n",
    "# %%\n",
    "print(f\"Extracting snapshots for times: {SNAPSHOT_TIMES} s\")\n",
    "\n",
    "da.extract_snapshots_at_times(\n",
    "    directory=DATA_DIRECTORY, \n",
    "    folders=reaction_folders, \n",
    "    target_timestamps=SNAPSHOT_TIMES\n",
    ")\n",
    "\n",
    "print(\"Workflow finished successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
